<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: testing | Rahul Nath]]></title>
  <link href="http://rahulpnath.com/blog/category/testing/atom.xml" rel="self"/>
  <link href="http://rahulpnath.com/"/>
  <updated>2016-03-31T04:21:22+11:00</updated>
  <id>http://rahulpnath.com/</id>
  <author>
    <name><![CDATA[Rahul Nath]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Refactoring Test Code: Removing Constructor Dependency]]></title>
    <link href="http://rahulpnath.com/blog/refactoring-test-code-removing-constructor-dependency/"/>
    <updated>2016-03-31T04:18:00+11:00</updated>
    <id>http://rahulpnath.com/blog/refactoring-test-code-removing-constructor-dependency</id>
    <content type="html"><![CDATA[<p><a href="https://www.flickr.com/photos/toomore/23066277453" class="center" title="Image By Toomore Chiang, from https://www.flickr.com/photos/toomore/23066277453"><img src="/images\testing.jpg" class="center" alt="Testing"></a></p>

<p>In the earlier post, <a href="http://rahulpnath.com/blog/refactoring-to-improve-testability-removing-unnecessary-dependencies/">Removing Unnecessary Dependencies</a>, we saw how having an unnecessary dependency hinders testability. In this post we will see how the test code changed by the refactoring we did for removing the unnecessary dependency and explore ways to control these changes.</p>

<h3>Impact on Tests by the Refactoring</h3>

<p>The refactoring in the last post involved a change in the updating the constructor signature to take in a string value instead of an interface. This broke a lot of our tests and forced us to change all constructor usages with the below code.</p>

<pre><code class="csharp">var anonymousName = "Anonymous Name";
myService = new MyService(otherDependency, anonymousName);
</code></pre>

<p>When seen in isolation, this is not much a change, but as the number of tests grows it becomes a pain. This definitely does not feel right. Breaking tests forces us out of <a href="http://xunitpatterns.com/test%20first%20development.html">Test-First Development</a> and reduces the confidence in the tests and in the code.</p>

<blockquote><p><em>The idea behind TDD was <a href="http://www.jamesshore.com/Blog/Red-Green-Refactor.html">Red-Green-Refactor</a>. But if tests break when Refactoring, then why follow TDD at all?</em></p></blockquote>

<h3>Refactoring Tests</h3>

<p>Ideally, we should write tests that do not break when we refactor, so that it helps us to use the same tests over the refactored code. Let&rsquo;s see how we can improve the test code to prevent tests from breaking, when we refactor to <a href="http://rahulpnath.com/blog/refactoring-to-improve-testability-removing-unnecessary-dependencies/">remove unnecessary dependency</a>. Below is the original code (<em>rewritten into xUnit and Moq, as I prefer that</em>) with the dependency on IAppSettings (which we will change it to string later)</p>

<pre><code class="csharp">[Fact]
public void PerformOperationsShouldReturnTrue()
{
    var otherDependency = new Mock&lt;IMyOtherDependency&gt;();
    var appSettings = new Mock&lt;IAppSettings&gt;();
    appSettings.Setup(a =&gt; a["app.name"]).Returns("My Test Application");
    var myService = new MyService(otherDependency, appSettings);

    var result = myService.PerformOperations();

    otherDependency.Verify(a =&gt; a.UtilityMethod(), Times.Once());
    Assert.True(result);
}
</code></pre>

<p>Let&rsquo;s analyze the test code for the dependencies that it has:</p>

<ul>
<li><em>UtilityMethod</em> of IMyOtherDependency</li>
<li><em>app.name</em> configuration value from IAppSettings</li>
<li><em>Constructor</em> of <a href="http://xunitpatterns.com/SUT.html">System Under Test</a>(SUT) - MyService</li>
<li><em>PerformOperations</em> of SUT which is getting tested</li>
</ul>


<p>The test by itself verifies that calling <em>PerformOperations</em> returns true and UtilityMethod gets called once. It is not dependent on the value (&lsquo;My Test Application&rsquo;) returned by appSettings. The only need is that it should return some (dummy) value when asked for &lsquo;app.name&rsquo;. Assuming that there are multiple tests in this class that does the same setup of IAppSettings to return a dummy value you can start smelling <em>Cut-and-Paste code reuse for fixture setup</em>.</p>

<blockquote><p><em>Rule of Three: “The first time you do something, you just do it. Second time you do something similar, you wince at the duplication, but you do the duplicate thing anyway. The third time you do something similar, you refactor.”</em></p></blockquote>

<p>The <a href="https://en.wikipedia.org/wiki/Rule_of_three_(computer_programming">Rule of Three</a> is applicable even when writing test code and we should always keep an eye for duplication. <strong>It is easy to get lost in the thought that it&rsquo;s just test code and does not hurt to copy paste</strong>. Code duplication in test code does hurt and it hurts the most when you refactor production code.</p>

<p>So lets Refactor applying the <a href="http://www.refactoring.com/catalog/">various techniques</a> that we know of!</p>

<h4><strong><a href="http://www.refactoring.com/catalog/extractMethod.html">Extract Method</a></strong></h4>

<p><em>You have a code fragment that can be grouped together. Turn the fragment into a method whose name explains the purpose of the method.</em></p>

<p>Since we only depend on the <em>IMyOtherDependency</em> and the SUT instance instantiated with that, we can extract SUT creation with a given instance of IMyOtherDependency as below.</p>

<pre><code class="csharp">[Fact]
public void PerformOperationsShouldReturnTrue()
{
    var otherDependency = new Mock&lt;IMyOtherDependency&gt;();
    var myService = GetMyServiceWithMyOtherDependency(otherDependency);

    var result = myService.PerformOperations();

    otherDependency.Verify(a =&gt; a.UtilityMethod(), Times.Once());
    Assert.True(result);
}

private MyService GetMyServiceWithMyOtherDependency(Mock&lt;IMyOtherDependency&gt; otherDependency)
{
    var appSettings = new Mock&lt;IAppSettings&gt;();
    appSettings.Setup(a =&gt; a["app.name"]).Returns("My Test Application");
    var myService = new MyService(otherDependency, appSettings);
    return myService;
}
</code></pre>

<p>This starts taking us towards <strong><a href="http://martinfowler.com/bliki/ObjectMother.html">Object Mother Pattern</a></strong>. It looks good to start with and might work well if all we have is the same <a href="http://xunitpatterns.com/Fixture%20Setup%20Patterns.html">fixture setup</a>. But if we have a different kind of fixture setup, with more dependency and combinations of setup, we will soon have a lot of similar creational methods with different combinations of parameters  - <em>GetMyServiceWithMyOtherDependencyAndAppSettings,GetMyServiceWithAppSettings</em> etc. The problem with having different methods is that all of them are dependent on the SUT constructor and set the same properties, leading to code duplication again.</p>

<h4><strong><a href="http://www.refactoring.com/catalog/extractClass.html">Extract Class</a></strong></h4>

<p><em>You have one class doing work that should be done by two. Create a new class and move the relevant fields and methods from the old class into the new class.</em></p>

<p>With these new creational methods the test class is having more responsibility than it should actually have, so let&rsquo;s extract these creation methods into <em>MyServiceBuilder</em> class to see if we can further solve the problem.</p>

<pre><code class="csharp">public class MyServiceBuilder
{
    public IAppSettings AppSettings { get; private set; }
    public IMyOtherDependency OtherDependency { get; private set; }

    public MyServiceBuilder()
    {
        var appsettingsMock = new Mock&lt;IAppSettings&gt;();
        appsettingsMock.Setup(a =&gt; a["app.name"]).Returns("My Test Application");
        AppSettings = appsettingsMock.Object;
        OtherDependency = new Mock&lt;IMyOtherDependency&gt;().Object;
    }

    public MyService Build()
    {
        return new MyService(OtherDependency, AppSettings);
    }

    public MyServiceBuilder WithAppSettings(IAppSettings appSettings)
    {
        AppSettings = appSettings;
        return this;
    }

    public MyServiceBuilder WithOtherDependency(IMyOtherDependency otherDependency)
    {
        OtherDependency = otherDependency;
        return this;
    }
}
</code></pre>

<p>This takes us to <strong><a href="http://www.natpryce.com/articles/000714.html">Test Data Builder Pattern</a></strong> and as we notice we have reduced the dependency on the MyService constructor to just one and only place where we need to change if the constructor signature changes. Since the <a href="https://en.wikipedia.org/wiki/Cyclomatic_complexity">Cyclomatic Complexity</a> of <em>MyServiceBuilder</em> is one it is fine not to write tests for it   . Using the new builder class our original test case now looks like below.</p>

<pre><code class="csharp">[Fact]
public void PerformOperationsShouldReturnTrue()
{
    var otherDependency = new Mock&lt;IMyOtherDependency&gt;();
    var myService = new MyServiceBuilder().WithOtherDependency(otherDependency.Object).Build();

    var result = myService.PerformOperations();

    otherDependency.Verify(a =&gt; a.UtilityMethod(), Times.Once());
    Assert.True(result);
}
</code></pre>

<p>Now the test is just dependent on the objects that it needs. If all the test use <em>MyServiceBuilder</em>, we can now easily refactor to <a href="http://rahulpnath.com/blog/refactoring-to-improve-testability-removing-unnecessary-dependencies/">Remove the Unnecessary Dependency</a> on IAppSettings, by just changing the <em>MyServiceBuilder</em> to use a string property. We will also need to change tests that use the <em>WithAppSettings</em> method which is expected, as those tests are dependent on the app settings value in the first place and so the tests definitely need to be re-written.</p>

<h3>Generic Test Data Builder</h3>

<p>We could have essentially stopped at the above step, but then we realize that it is too much work to create a Test Data Builder class for each of the production code classes that we have. It takes a lot out of the <a href="http://keysleft.com/">finite number of keystrokes left in your hands</a> and you definitely don&rsquo;t want to waste that in typing redundant code. This is where we can use
<a href="https://github.com/AutoFixture/AutoFixture">AutoFixture</a>, that is an open source library for .NET that helps reduce the <a href="http://xunitpatterns.com/Four%20Phase%20Test.html">Setup</a>/<a href="http://c2.com/cgi/wiki?ArrangeActAssert">Arrange</a> phase. Using <a href="http://blog.ploeh.dk/2010/10/08/AutoDataTheorieswithAutoFixture/">AutoData Theories with AutoFixture</a> our test case now looks like below.</p>

<pre><code class="csharp">[Theory, AutoMoqData]
public void PerformOperationsShouldReturnTrue(
    [Frozen]Mock&lt;IMyOtherDependency&gt; otherDependency,
    MyService myService)
{
    var result = myService.PerformOperations();

    otherDependency.Verify(a =&gt; a.UtilityMethod(), Times.Once());
    Assert.True(result);
}
</code></pre>

<p>The test code does not have any dependency on the constructor of the SUT and a change in constructor signature does not affect our tests at all. We can refactor <em>MyService</em> and use the same tests as long as the functionality served by the class remains the same. Constructors are implementation details and it&rsquo;s better to keep tests independent of it. This keeps our test code clean and more robust!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Refactoring to Improve Testability: Removing Unnecessary Dependencies]]></title>
    <link href="http://rahulpnath.com/blog/refactoring-to-improve-testability-removing-unnecessary-dependencies/"/>
    <updated>2016-03-28T04:27:00+11:00</updated>
    <id>http://rahulpnath.com/blog/refactoring-to-improve-testability-removing-unnecessary-dependencies</id>
    <content type="html"><![CDATA[<p><a href="https://unsplash.com/photos/5Ntkpxqt54Y" class="center" title="Image By Sai Kiran Anagani, from https://unsplash.com/photos/5Ntkpxqt54Y"><img src="/images\refactoring.jpg" class="center" alt="Refactoring"></a></p>

<p>Nowadays I am trying to stick to <a href="http://butunclebob.com/ArticleS.UncleBob.TheThreeRulesOfTdd">TDD</a> (with the test first approach) and have found it to be of great help. One of the biggest reward doing TDD is that it helps me to <a href="https://vimeo.com/97419151">stay in the flow</a> and regain speed faster after a distraction. This post explains how to refactor code to remove unnecessary dependencies, which is easily found when writing tests.</p>

<p>Unnecessary dependencies are those components which a <a href="http://xunitpatterns.com/SUT.html">SUT</a> depends on, but does not directly affect any of its functionalities. Some of the common tests smell (from XUnit Test Patterns by Gerard Meszaros, <a href="http://www.rahulpnath.com/blog/language-agnostic-books-for-every-developer-2/">a recommended read</a>) that helps me to find these dependencies are <a href="http://xunitpatterns.com/Test%20Code%20Duplication.html">Test Code Duplication</a> and <a href="http://xunitpatterns.com/Fragile%20Test.html">Fragile Tests</a>.</p>

<blockquote><p><em>Cut-and-Paste code reuse for fixture setup happens often when there is an unnecessary dependency.</em></p></blockquote>

<p>While looking for an example to write on, I came across a post from my friend <a href="https://twitter.com/zpbappi">Bappi</a>, where he explains <a href="http://zpbappi.com/testing-codes-with-configurationmanager-appsettings/">Testing Codes with ConfigurationManager</a>. It&rsquo;s a good read on how to remove the dependency with various Configuration Providers by creating an abstraction over it.</p>

<h3>Testability Issues with Current Design</h3>

<p>While abstracting the Configuration Manager by using an interface is a good idea, you should also be careful on how the application classes depend on it. Configurations live at the application root and it is a good idea to restrict dependencies with it at that level. Rest of the application must be dependent only on the configuration value and not the configuration itself. Inner components having dependency with the  configuration provider brings in unnecessary complexities and makes code fragile. Some common issues are</p>

<ul>
<li>Class needs to know of Configuration key</li>
<li>Extra mocking while testing</li>
</ul>


<p>As you see below, the test case from the original post has to set up the Configuration provider mock to return values before testing the class. MyService (assuming that it is not a Factory class, which I confirmed from Bappi) is unnecessarily depending on IAppSettings and coupling itself with the configuration name, which really is not its concern. This leads to brittle code and tests!</p>

<pre><code class="csharp">[Subject(typeof(MyService))]
public class MyServiceTests
{
    Establish context = () =&gt;
        {
            otherDependency = Substitute.For&lt;IMyOtherDependency&gt;();

            var appSettings = Substitute.For&lt;IAppSettings&gt;();
            appSettings["app.name"].Returns("My Test Application");

            myService = new MyService(otherDependency, appSettings);
        };

    Because of = () =&gt; result = myService.PerformOperations();

    It should_call_my_dependency_utility_method_once = () =&gt; otherDependency.Received(1).UtilityMethod();
    It should_execute_successfully = () =&gt; result.ShouldBeTrue();
}
</code></pre>

<h3>Refactoring the Code</h3>

<p>Refactoring such code is as easy as removing the dependency on IAppSettings and taking in the value of &lsquo;app.name&rsquo; as the dependency. This removes the interface dependency and requires only the string value to be passed in. Here I am passing in <a href="https://blogs.msdn.microsoft.com/ploeh/2008/11/17/anonymous-variables/">an anonymous Name</a>, as the value is not of concern for this test.</p>

<pre><code class="csharp">[Subject(typeof(MyService))]
public class MyServiceTests
{
    Establish context = () =&gt;
        {
            otherDependency = Substitute.For&lt;IMyOtherDependency&gt;();
            var anonymousName = "Anonymous Name";
            myService = new MyService(otherDependency, anonymousName);
        };

    Because of = () =&gt; result = myService.PerformOperations();

    It should_call_my_dependency_utility_method_once = () =&gt; otherDependency.Received(1).UtilityMethod();
    It should_execute_successfully = () =&gt; result.ShouldBeTrue();
}
</code></pre>

<blockquote><p><em>When looked at isolation these are minor code changes that hardly removes a line or two. But it has a cumulative effect when applied to all the tests for the class and makes code more robust.</em></p></blockquote>

<p>When looked at isolation, this is a seemingly minor change of not mocking an interface and is just one line of code, which you could live with. But you need to mock that for all tests of that class, which is when you start to see the real benefit. Also, you have made the tests more resilient by not taking an unnecessary dependency. Even if you decide to change the configuration name to &lsquo;<em>ApplicationName</em>&rsquo;, none of the tests break now, whereas with the original code all of them would have.</p>

<p><em>One possible argument with this refactoring is, <strong> What if I need an extra value from the dependency (app.domain in the above case), I now have to update the class constructor</strong>.</em></p>

<p>Agreed, but then this violates <a href="https://blog.8thlight.com/uncle-bob/2014/05/12/TheOpenClosedPrinciple.html">Open Closed Principle</a>, which states &lsquo;You should be able to extend a classes behaviour without modifying it.&rsquo; If you need a new configuration value, you are essentially changing the components functionality, so you should either extend current functionality or write a new component. This also opens up a hidden code smell with the existing code and an anti-pattern - <a href="http://blog.ploeh.dk/2010/02/03/ServiceLocatorisanAnti-Pattern/">Service Locator</a>. So the refactoring still holds good!</p>

<p>Hope this helps you find dependencies with unnecessary components and remove them.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using Fiddler to help in Manual Testing]]></title>
    <link href="http://rahulpnath.com/blog/using-fiddler-to-help-in-manual-testing/"/>
    <updated>2016-03-07T17:33:00+11:00</updated>
    <id>http://rahulpnath.com/blog/using-fiddler-to-help-in-manual-testing</id>
    <content type="html"><![CDATA[<p>Fiddler is an HTTP debugging proxy server application, that captures HTTP and HTTPS traffic and displays to the user. It also enables modifying HTTP traffic when sent or received. Fiddler is <a href="http://www.rahulpnath.com/blog/tools-that-I-use/">one of the tools that I use daily</a> and is an indispensable one for any web developer.</p>

<p>This post gives an introduction on how you can use fiddler to help with &lsquo;manual testing&rsquo;. We will see how to use Fiddler to create requests to Web API,  modify and replay an existing request. We will also see how to test error scenarios to see how the application functions in those cases. The sample solution is the default Web API project in Visual Studio with a few changes.</p>

<h3>Composing a Request</h3>

<p>When testing API&rsquo;s to see how it behaves with various inputs, one often needs to send in different parameters. Fiddler allows composing new requests and  modifying existing ones.</p>

<p>Using the Fiddler composer window (shown in the image below), we can create new requests from scratch and execute them. It provides two modes to create requests:</p>

<ul>
<li>Parsed : This is an assisted form to create requests</li>
<li>Raw : This allows to create raw http requests and issue them.</li>
</ul>


<p>Fiddler also allows saving raw requests in the Scratchpad tab to execute as and when required. On clicking Execute Fiddler creates an HTTP request from the entered data and sends to the server. To modify requests you can either drag and drop the request from the displayed URL&rsquo;s list into the composer tab or right-click on an entry and <em>Unlock for Editing</em> (keyboard shortcut - F2). After making the changes to the request in the Inspector window, right-click on the request again to Replay -> Reissue ( R).</p>

<p><img class="center" alt="Fiddler Composer tab" src="/images/fiddler_composer.png" /></p>

<h3>Testing Error Cases</h3>

<p>Testing error cases is tricky, especially from a UI level. Things usually don&rsquo;t go wrong in the development/testing environment and <a href="http://blog.codinghorror.com/the-works-on-my-machine-certification-program/">almost never on a developers machine</a> which makes it very hard to test for cases where something does not work. Fiddler makes it easy to test error scenarios with <a href="http://docs.telerik.com/fiddler/KnowledgeBase/AutoResponder">AutoResponder</a>, which allows returning handcrafted responses for requests, without actually hitting the server.</p>

<p>To create an auto response for a URL, select the URL from the URL&rsquo;s list and drag it into the AutoResponder tab or select the URL and click on Add Rule button on AutoResponder tab, which will create a new rule. By default Fiddler creates a rule with an exact match (Exact:) with the selected URL. Fiddler supports different <a href="http://docs.telerik.com/fiddler/KnowledgeBase/AutoResponder#matching-rules">matching rules</a> which include regular expression matches. A list of default response text are available to choose from to respond to requests that match the URL matching rule. We can also create a custom response and save it for reuse. The next time a request with matching URL is found the custom response gets returned to the caller.</p>

<blockquote><p><em>Make sure that the &lsquo;Unmatched requests passthrough&rsquo; option is true in the AutoResponder tab to make sure that all other requests pass through to the server.</em></p></blockquote>

<p><img class="center" alt="Fiddler AutoResponder tab" src="/images/fiddler_autoresponder.png" /></p>

<p>To create a custom response, choose &lsquo;Create a New Response&rsquo; or &lsquo;Find a file&rsquo; (if you already have the response saved in a text file). You can save custom responses in the <em>ResponseTemplates</em> folder in the root folder of Fiddler installation, to have them populated in the AutoResponder tab. When editing existing response data, make sure properties like Content-Length reflects the correct values. You can also set a <a href="http://docs.telerik.com/fiddler/KnowledgeBase/AutoResponder#latency">Latency</a> for the response, to simulate response coming from a server. RIght click on the rules for the Set Latency option and enter the value in milliseconds.</p>

<p>With the AutoResponder set to matching URL, we can easily have it return error codes or simulated error messages to test how the UI handles them. You don&rsquo;t have to depend on &lsquo;actual server errors&rsquo; to test if the UI handles error correctly. You can use this to test how application behaves with different return values by mocking with valid custom responses.  Fiddler provides richer capabilities of using scripts to <a href="http://docs.telerik.com/fiddler/KnowledgeBase/FiddlerScript/ModifyRequestOrResponse">modify a request or response</a>.</p>

<p>Hope this helps you get started with using Fiddler for testing and manipulating requests/responses.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Organizing Tests into Test Suites for Visual Studio]]></title>
    <link href="http://rahulpnath.com/blog/organizing-tests-into-test-suites-for-visual-studio/"/>
    <updated>2016-01-18T22:51:03+11:00</updated>
    <id>http://rahulpnath.com/blog/organizing-tests-into-test-suites-for-visual-studio</id>
    <content type="html"><![CDATA[<p>While working with large code base, that has a lot of tests (unit, integration, acceptance etc), running all of them every time we make a small  change (if you are doing TDD or just using build for feedback) takes a lot of time. Organizing tests into different test suites, making it easier to run as required by the current context, is handy in such cases.</p>

<p>There are multiple ways that we can do this within Visual Studio and below are some of the options available. I tend to use a mix of all these in my current project. This gives the flexibility to run only the new tests that I am writing while writing new code or set of related tests for the updates that I am making. Once done with the changes, I can run the full suite of unit tests, followed by the integration tests. This reduces the interruption duration while coding and has a direct impact on the overall productivity too. (If you think small interruptions does not matter much think twice!)</p>

<p><img class="center" alt="Geek productivity" src="/images/geek_productivity.jpg" /></p>

<h4><strong>Test Traits</strong></h4>

<p>Traits are a good way to group tests together and to run them as different suites. It encompasses TestCategory, TestProperty, Priority and Owner. Using <a href="https://msdn.microsoft.com/en-au/library/microsoft.visualstudio.testtools.unittesting.testcategoryattribute.aspx">TestCategory</a> attribute we can specify  the group of the test and the Visual Studio Test Explorer uses this value to group the tests and allows executing tests in specific groups.</p>

<p><img class="center" alt="Visual Studio Test Traits" width="75%" src="/images/vs_testExplorer_traits.png" /></p>

<p>Limitation with the above approach is that it depends on developers to put these attributes on the test cases or class level and not leveraging any existing conventions that might be already in place. Having integration tests, unit tests, acceptance tests in different projects is a very common practice, with conventions like project names ending with &lsquo;.UnitTests, .IntegrationTests, .AcceptanceTests&rsquo; etc.</p>

<h4><strong>Build Tasks and Task Runner Explorer</strong></h4>

<p>The <a href="https://visualstudiogallery.msdn.microsoft.com/8e1b4368-4afb-467a-bc13-9650572db708">Task Runner Explorer</a> (TRE) provides custom task runner support to Visual Studio, allowing to run grunt/gulp task or target inside Visual Studio. Grunt/Gulp has packages for most of the unit testing frameworks, using which different build tasks can be created. To select the tests to execute different conventions can also be used. Below is an example of a gulp task to execute all the c# unit tests in the project.</p>

<pre><code class="javascript">var gulp = require('gulp');
var xunit = require('gulp-xunit-runner');
var xunitConsolePath = 'xunit.console.exe';
var unitTestsConvention = ['**/*.Tests.dll'];

gulp.task('c#UnitTests', function () {
    runTests(unitTestsConvention);
});

function runTests(dllPath) {
    return gulp.src(dllPath, { read: false })
        .pipe(xunit({
            executable: xunitConsolePath,
            options: { parallel: 'all' }
        }));
}
</code></pre>

<p>Similarly we can have multiple tasks to execute different groups of tests and it will be available in the TRE within Visual Studio as shown below. This approach gives the most flexibility, allowing tests be grouped any way and providing ability to execute tests across the stack of technologies.
<img class="center" alt="Visual Studio Task Runner Explorer" src="/images/vs_tre.png" /></p>

<h4><strong>Tests Settings File</strong></h4>

<p>Creating Test Playlist is an easy way to group tests into a playlist and executing them as  group. From the Test Explorer, select the tests to be grouped and on right-click, the option to create playlist is available. The saved playlists can be selected from the drop down menu on the top bar for later execution.</p>

<p><img class="center" alt="Visual Studio Test Playlist" src="/images/vs_testExplorer_playlist.png" /></p>

<p>This works well for short-lived groupings, when we are actively working on a part of the code and need to execute tests for that area. Every time a new test is added, we need to add it explicitly to the playlist if required.</p>

<p>We have seen multiple ways of grouping tests into test suites, and each of them comes handy in different situations. For project wide convention tests, I tend to use build tasks that integrate with TRE as it is more flexible and extendable. Do you use any other ways to group your tests, drop in with a comment!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Testing Multiple Implementations of same Interface]]></title>
    <link href="http://rahulpnath.com/blog/testing-multiple-implementations-of-same-interface/"/>
    <updated>2015-01-10T15:54:15+11:00</updated>
    <id>http://rahulpnath.com/blog/testing-multiple-implementations-of-same-interface</id>
    <content type="html"><![CDATA[<p>Often there are times when we need to test multiple implementations of the same interface. We would want to use the same test case against all the implementations so that we <a href="http://en.wikipedia.org/wiki/Don%27t_repeat_yourself">don&rsquo;t repeat ourselves</a>. In this post we will see how we can reuse the same test cases to test both the implementation, by running them against both the implementations.</p>

<blockquote><p>If you are just interested in the approach - The same test project dll is run twice using vstest.console, by setting an environment variable. Inside the test, (either in the assembly initialize or test initialize) register the appropriate implementations into a IoC container, based on the environment variable value.</p></blockquote>

<p>Interested in the full implementation, then read on!</p>

<p>Since we are not much bothered about the actual interface and its implementation, I have a very simple interface as below, which calculates the length of the given string.There are two implementations for this that might have two different ways of calculating the length of the string given an input.</p>

<pre><code class="csharp">public interface IFoo
{
    int GetLength(string input);
}
</code></pre>

<pre><code class="csharp Implementation 1">public class Foo : IFoo
{
    public int GetLength(string input)
    {
        return input.Count();
    }
}
</code></pre>

<pre><code class="csharp Implementation 2">public class Foo : IFoo
{
    public int GetLength(string input)
    {
        return input.Length;
    }
}
</code></pre>

<p>Though the sample has a simple interface, this might not be the case in a real life project. So the sample mimics a real time implementation structure - we have one interface project and two other projects that have the corresponding implementation. The implementations could also be in the same assembly and this would be applicable for those scenarios too, and can be made to work with some few tweaks in one of the steps (which I will mention when we are there). The test case project that will have the appropriate test cases.</p>

<pre><code class="csharp">[TestMethod]
public void TestThreeLetterLength()
{
    var foo = this.container.Resolve&lt;IFoo&gt;();
    var returnValue = foo.GetLength("Foo");
    Assert.IsTrue(returnValue == 3);
}
</code></pre>

<p>The test case uses the IoC container to get the corresponding implementation of the interface, so it is not all about switching the registered implementation in the container. If this is only for the tests in this particular class then we could do this in the <a href="http://msdn.microsoft.com/en-us/library/microsoft.visualstudio.testtools.unittesting.testinitializeattribute.aspx">TestInitialize</a> method. But most likely you would have multiple tests and also multiple interfaces that we are using. So we can do this in the <a href="http://msdn.microsoft.com/en-us/library/microsoft.visualstudio.testtools.unittesting.assemblyinitializeattribute.aspx">AssemblyInitialze</a> for the assembly.</p>

<pre><code class="csharp Interface">var test = Environment.GetEnvironmentVariable(TestEnviromentVariable);

if (test == "1")
{
    container.RegisterType&lt;IFoo, FooImplementation1.Foo&gt;();
}
else if (test == "2")
{
    container.RegisterType&lt;IFoo, FooImplementation2.Foo&gt;();
}
</code></pre>

<p>The above implementation might work in cases where the number of interfaces are less and also in cases where we have fewer possibilities of implementations, but as soon as the number goes up we will again have to keep repeating  the registrations and the if/else code. This is an IoC registration issue and is best handled using <a href="http://www.rahulpnath.com/blog/ioc-registration-by-convention/">IoC Registration by Convention</a>. We can have a configuration file matching the environment variable and have the assemblies that are to be loaded mentioned in that and pass only those assemblies to be explicitly registered into the convention registration logic. Even in cases where you have the implementations in the same assembly you can write your convention registration logics accordingly and decide what to register.</p>

<p>We can now run these test dll&rsquo;s using batch files by setting different environment variables as below. The bat files can be integrated into your build</p>

<pre><code class="bat FooTest.Implementation2.bat">set Foo.tests=2
echo "Testing for configuration 2"
msbuild TestingMultipleImplementations.sln
vstest.console FooTestImpl1\bin\Debug\FooTestImpl1.dll /logger:trx
</code></pre>

<p>Hope this helps some one trying to reuse test cases for multiple implementations of the same interface. One another way to solve this issue would be to create multiple csproj files and have the same test case classes referred to both the project files, but have the reference assemblies specific to implementations. So in this case we would have multiple test dll&rsquo;s created, which can be run individually. The advantage of going via this approach is that we could have test cases specific to implementations too and also reuse test cases that are same across implementations by referring them as linked files. But currently we did not want this flexibility and did not want to add multiple project files and make it difficult for the team. You can find the sample implementation <a href="https://github.com/rahulpnath/Blog/tree/master/TestingMultipleImplementations">here</a>. Do you reuse test cases like this? Do drop in with a comment on your thoughts.</p>
]]></content>
  </entry>
  
</feed>
