<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: programming | Rahul Nath]]></title>
  <link href="http://rahulpnath.com/blog/category/programming/atom.xml" rel="self"/>
  <link href="http://rahulpnath.com/"/>
  <updated>2016-05-18T12:46:02+10:00</updated>
  <id>http://rahulpnath.com/</id>
  <author>
    <name><![CDATA[Rahul Nath]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Make it Easy for the New Person Joining the Team - Have a Project Ramp up Plan]]></title>
    <link href="http://rahulpnath.com/blog/make-it-easy-for-the-new-person-joining-your-team-have-a-project-ramp-up-plan/"/>
    <updated>2016-05-18T12:38:24+10:00</updated>
    <id>http://rahulpnath.com/blog/make-it-easy-for-the-new-person-joining-your-team-have-a-project-ramp-up-plan</id>
    <content type="html"><![CDATA[<p>Recently I was in a discussion with my friend/colleague on conducting a few ramp up sessions for the new hires in our team. The discussion went as below,</p>

<blockquote><p><em>Me: We should hold a few sessions to make the new guys in team more comfortable</em></p>

<p><em>Friend: It&rsquo;s too early for it. We should let them find their own way and not &lsquo;spoon-feed&rsquo; them with information.</em></p>

<p><em>Me: But we are not &lsquo;spoon-feeding&rsquo; them, we are just making their learning process faster and giving then an overview on how all the technology fits together in our world of things.</em></p>

<p><em>Friend: But &lsquo;I did not have any ramp up when I joined, and I felt it was better to have learned it on my own, though it took a lot more time.</em></p></blockquote>

<p><a href="http://www.mindtickle.com/wp-content/uploads/2014/02/new_employee_orientation_business_strategy_research.png" class="center" title="Image, from http://www.mindtickle.com/wp-content/uploads/2014/02/new_employee_orientation_business_strategy_research.png"><img src="/images\rampup_plan.png" class="center" alt="Rampup Plan"></a></p>

<p>Just like there are company-wide induction/onboarding sessions, I have always felt that project specific onboarding plans are also required and help new hires be part of the team and be more productive with their day-to-day activities faster. As mentioned in this <a href="http://www.fastcompany.com/3029820/work-smart/infographic-the-real-ways-to-hold-on-to-new-hires/3">article</a>, <em>New hires care more about effective job training and clear guidelines, and it&rsquo;s time you provide that for them.</em> It&rsquo;s best to have a plan in place when you have someone new joining your team and you along with the team are the best people to put that plan together.</p>

<h3>Boy Scout Rule</h3>

<p>The Boy Scouts have a <a href="http://programmer.97things.oreilly.com/wiki/index.php/The_Boy_Scout_Rule">rule</a> - <em>&ldquo;Always leave the campground cleaner than you found it.&rdquo;</em>  New hires are like &lsquo;new camp group&rsquo; at a campground, so it&rsquo;s the duty of the &lsquo;existing team&rsquo; there to make it a good experience for them.</p>

<blockquote><p><em>&lsquo;Refactor&rsquo; your experiences to make it better for the next person who is about to take on the same journey</em></p></blockquote>

<p>It&rsquo;s not that my friend was intentionally trying not to pass on any information, but he felt that learning on their own would be better. Even I agree with him that learning on your own is far better than &lsquo;spoon-feeding&rsquo; - but a ramp up plan is not spoon-feeding. A ramp up plan is only to speed up the learning process and to make it more comfortable for someone joining new.</p>

<h3>When to create the plan?</h3>

<p>The need for such a plan is there only when there has been enough progress made on the project, after which there is someone new joining the team. So when a new hire is scheduled to join is a good time to create the &lsquo;draft&rsquo; plan. Once the new hire has gone through it and updated back with his own experiences it could become the first version of the plan, which can then be confidently shared to anyone joining after as it has worked for at least one person.</p>

<h3>What should be there in the plan</h3>

<p><em>It depends!</em></p>

<p>It&rsquo;s totally up to the team to decide what should be there in the plan. Some of the things that I usually have are</p>

<ul>
<li><p><strong>Overview of the project and what problem it is trying to solve</strong></p>

<p>It&rsquo;s really important that everyone on the team knows what the application is trying to solve and have a common goal to work towards. It&rsquo;s not just about the code we write but about the problem we are solving and that needs to be clearly defined. I would record a video, when this is done the first time and share it with anyone joining after that, as most of the core concepts of a project rarely change. There could be a follow-up session post watching the video, to also have a quick walk through and fill any missing gaps.</p></li>
<li><p><strong>Introduction to various technologies used in the project and how everything fits together</strong></p>

<p>Technology changes so fast these days that it is nearly impossible to stay updated with all the available options. So a walk through of the different technologies and pointers to resources that worked for you and the team will be of help. If there are any specific libraries, frameworks getting used, an introduction to those should also help.</p></li>
<li><p><strong>Release cycle and Release management</strong>
Every project has its own model of delivering the end product and everyone on the team should understand this process well. Having a continuous build is becoming more common these days and helps reduce the complexity of release. An end to end walk-through of the deployment process helps understand the application better and provides exposure to all the moving parts in the system.</p></li>
<li><p><strong>Environment/Machine setup</strong>
Software installation is one of the biggest pain when setting up a new machine for a project, especially with having specific versions of the software. Having a documented list of all the project dependencies (hardware and software) makes setting the project environment easy. It&rsquo;s preferable to have these <a href="https://chocolatey.org/">scripted</a>. Have a common place, where you can find links to all the various environments (dev, at,prod etc) and related resources.</p></li>
<li><p><strong>Patterns and Conventions</strong>
Every project has its own conventions and certain core patterns that are followed. It&rsquo;s good to have these patterns available for reference so that it helps understand the code better and helps reduce code-review cycles. Than having one big boring document, what I prefer more is to have multiple blog articles targeting each of those. I try to generalize commonly used patterns in the projects that I have worked on and create blog posts. This also helps generate content for <a href="http://www.rahulpnath.com/blog/get-started-with-your-blog/">your blog</a>.</p></li>
<li><p><strong>Tips &amp; Tricks</strong>
This could range from how to easily navigate the code base, scripts to do some commonly occurring task and general things to keep an eye for.</p></li>
</ul>


<p>These are just some of the things I generally try to include in a ramp up plan but as said it totally depends on the team and the project.</p>

<h3>Sharing the plan</h3>

<p>Depending on the plan, if it has confidential information, you could split this into two (or more) different documents and share it at different phases of onboarding. Once a new hire is confirmed it&rsquo;s good to share the parts which do not have any confidential information. Technology stack, conventions used, machine setup (<a href="https://en.wikipedia.org/wiki/Bring_your_own_device">BYOD</a>) are usually not confidential and can be shared well before actual employment. Once all employment agreements are in place the rest too can be shared. It&rsquo;s also a good idea to have some walk-through of the plan itself to make it easier to follow.</p>

<h3>Iterate and Improve</h3>

<p>Updating back with the experiences of the people using the plan is important to keep it current and valuable. Suggesting improvements and updates should be an item in the plan so that this does not get missed. To make updates manageable, the plan must be accessible to all and preferably version controlled if they are documents.</p>

<p>What are your thoughts on having a ramp up plan?</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Disable NuGet Package Restore for a .Net Poject]]></title>
    <link href="http://rahulpnath.com/blog/disable-nuget-package-restore-for-a-net-poject/"/>
    <updated>2016-05-02T13:26:59+10:00</updated>
    <id>http://rahulpnath.com/blog/disable-nuget-package-restore-for-a-net-poject</id>
    <content type="html"><![CDATA[<p><em>If you have decided on <a href="http://www.rahulpnath.com/blog/checking-in-package-dependencies-into-source-control/">Checking in Package Dependencies into Source Control</a> for an existing project that uses Nuget Packages then this post is for you</em></p>

<p>When using NuGet package references that are not included in the source control, these packages gets restored during build time. There are <a href="https://docs.nuget.org/consume/package-restore">multiple ways that NuGet supports restore these dependencies at build time</a></p>

<ul>
<li>Automatic Package Restore is the current recommended approach (within Visual Studio), which is available from NuGet 2.7.</li>
<li>Command-line package restore on build servers</li>
<li>MSBuild-integrated package restore approach is the original Package Restore implementation and is still used in many projects.</li>
</ul>


<p>Depending on the type to of restore the project uses, NuGet has different configuration entries in the <em>csproj</em> files and <em>.nuget</em> folder in the solution root. So when choosing to check in package dependencies into the source control, it is a good idea to remove all these <a href="https://docs.nuget.org/consume/package-restore/migrating-to-automatic-package-restore">generated configurations</a> and files that are not required any more. The below script does this for you!</p>

<div class="alert alert-warning">
<strong>WARNING!</strong> The script deletes the <em>.nuget</em> folder (if it exists), updates the <em>.csproj</em> files. Please make sure that the project folder is under source control or you have a backup of the folder. After running the script make sure that all the changes that you see are expected as explained here and the project builds and runs as before.
</div>


<p>The PowerShell script does the below for a given solution directory folder (mandatory)</p>

<ul>
<li>For each of the <em>csproj</em> file in the given folder, the script removes the

<ul>
<li><em>RestorePackages</em> node</li>
<li><em>NugetPackageImportStamp</em> node</li>
<li><em>nuget target import</em> from the solution root .nuget folder</li>
<li><em>EnsureNuGetPackageBuildImports</em> node</li>
</ul>
</li>
<li>Removes <em>.nuget</em> folder from the solution root if it exists.</li>
</ul>


<p><em>The script leaves blank lines in the </em>csproj<em> files in place of the removed nodes.</em></p>

<pre><code class="powershell Remove NuGet Restore https://gist.github.com/rahulpnath/13d3b4f54cec51e22344876b1566b911#file-remove-nuget-restore-ps1">param([Parameter(Mandatory=$true)][string]$solutionDirectory) 

 $importNugetTargetsTag= [regex]::escape(@'
&lt;Import Project="$(SolutionDir)\.nuget\NuGet.targets" Condition="Exists('$(SolutionDir)\.nuget\NuGet.targets')" /&gt;
'@)

$restorePackagesTag = '&lt;RestorePackages&gt;.*?&lt;/RestorePackages&gt;'
$nuGetPackageImportStamp = '&lt;NuGetPackageImportStamp&gt;.*?&lt;/NuGetPackageImportStamp&gt;'

$EnsureNuGetPackageBuildImportsTargetTag = '(?smi)&lt;Target Name="EnsureNuGetPackageBuildImports".*?&lt;/Target&gt;'

foreach ($f in Get-ChildItem -Recurse -Path $solutionDirectory -Filter *.csproj | sort-object)
{
    $text = Get-Content $f.FullName -Raw
    $text `
        -replace $importNugetTargetsTag, "" `
        -replace $nuGetPackageImportStamp, "" `
        -replace $restorePackagesTag, "" `
        -replace $EnsureNuGetPackageBuildImportsTargetTag, "" `
        | set-content $f.FullName
}

Get-ChildItem -Path $solutionDirectory -include .nuget -Recurse | foreach ($_) { remove-item $_.fullname -Force -Recurse }
</code></pre>

<p>Any similarity with the scripts <a href="http://weblogs.asp.net/jongalloway/scripting-net-project-migration-to-automatic-nuget-package-restore">here</a> is intended as that was my starting place. To explicitly <a href="https://docs.nuget.org/consume/package-restore#opting-out">opt out of the Automatic Package Restore</a> on Visual Studio add a <em>Nuget.config</em> in the solution root.
&#8220;` xml
&lt;?xml version=&ldquo;1.0&rdquo; encoding=&ldquo;utf-8&rdquo;?>
<configuration>
  <packageRestore>
    <!-- Opts out of both Automatic Package Restore and MSBuild-Integrated Package Restore -->
    <add key="enabled" value="False" /></p>

<pre><code>&lt;!-- Opts out of Automatic Package Restore in Visual Studio --&gt;
&lt;add key="automatic" value="False" /&gt;
</code></pre>

<p>  </packageRestore>
</configuration>
&#8220;`</p>

<p>Hope this helps you to move away from NuGet restore at build time.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Checking in Package Dependencies into Source Control]]></title>
    <link href="http://rahulpnath.com/blog/checking-in-package-dependencies-into-source-control/"/>
    <updated>2016-04-26T12:21:21+10:00</updated>
    <id>http://rahulpnath.com/blog/checking-in-package-dependencies-into-source-control</id>
    <content type="html"><![CDATA[<p><em>This post looks into why we should include packages in the source control and not resolve it via configuration files at build time.</em></p>

<p>Over the past few years, <a href="https://en.wikipedia.org/wiki/Package_manager">Package Managers</a> have gained an important role in the way software gets developed. There is an <a href="https://github.com/showcases/package-managers">increasing number of package managers</a> catering to different programming languages and areas of development, making the distribution of reusable libraries and plugins easy. The convention that&rsquo;s usually followed with these package dependencies is to exclude them from source control, and use a configuration file (<a href="https://docs.npmjs.com/files/package.json">package.json</a>, <a href="https://docs.nuget.org/consume/package-restore">packages.config</a>) to retrieve all the packages at build time. Even the <a href="https://github.com/github/gitignore">GitHub’s collection</a> of <a href="https://git-scm.com/docs/gitignore">.gitignore</a> file templates ignores the packages folders of various package managers.</p>

<pre><code class="text"># NuGet Packages
*.nupkg
# The packages folder can be ignored because of Package Restore
**/packages/*
...
# Dependency directories
node_modules
jspm_packages
</code></pre>

<h3>Common Arguments for not Checking in Packages</h3>

<p>Since checking in packages is not a common practice, let&rsquo;s first see some of the arguments for not doing this and how it compares to having them checked in.</p>

<h4><strong>Storage</strong></h4>

<p><em>Packages are something that can be resolved at runtime and keeping them excluded saves that extra space on the source control system.</em></p>

<p>Yes, this might have been a good reason few years back, but these days this is not a good reason as storage has become really cheap. Moreover popular source control systems charge by the <a href="https://github.com/pricing/plans">number of repositories</a> and not by the space it occupies (although it has <a href="https://help.github.com/articles/what-is-my-disk-quota/">limits</a> on it).</p>

<h4><strong>Time</strong></h4>

<p><em>The clone is faster when you do not have packages in the source control repository as opposed to having them.</em></p>

<p>But for the project to build we need the packages restored first. So the time is either spent in the clone or in the restore. But if the packages are included in the git clone then you can immediately start working on the project after a clone and do not need any internet connectivity to make the project build. This is also of advantage if you want to run a &lsquo;<a href="https://git-scm.com/docs/git-clean">git clean</a>&rsquo; - which cleans the working tree by recursively removing files that are not under version control. With packages not under the source control, you have to restore them every time you run it - This is not a problem if you have internet connectivity, but will block your work if you do it when you don&rsquo;t.</p>

<blockquote><p><em>Without checking in dependent packages, you can&rsquo;t git clone and get on a flight nor can you git clean while on a <a href="https://en.wikipedia.org/wiki/Airplane_mode">flight</a></em></p></blockquote>

<p>Moreover cloning a repository is a one-time activity, while a clean can be done any time a developer wants to. So it actually saves more time to keep the packages checked in.</p>

<h3>More Reason for Checking in Packages</h3>

<p>Now that we have seen most of the common arguments are not valid, let&rsquo;s see more reasons on why including the packages into the source control is actually better.</p>

<h4><strong>Explicit Dependencies</strong></h4>

<p>It&rsquo;s always better to be explicit about your code dependencies and not have them resolved by a package manager.</p>

<blockquote><p><em>Packages are nothing but code and can alter the behaviour of the application.</em></p></blockquote>

<p>There are possibilities of specific package versions getting <a href="http://blog.npmjs.org/post/141577284765/kik-left-pad-and-npm">removed from the package manager</a>, which your application is still dependent on and leads to build breakage! If your package configuration is set up in such a way to resolve the latest available package of  the specific dependency, there are possibilities that the package owner pushes an update that is not backward compatible, causing the build to break! Given that these possibilities exist there is no reason to exclude package dependencies from checked in.</p>

<h4><strong>Package Source Downtime</strong></h4>

<p>Though the publicly available package sources like NuGet, npm are available almost all the time, it is likely that they too <a href="http://stackoverflow.com/questions/17806889/nuget-feed-reliability">can go down</a>. The last thing you would want is to get blocked by the downtime of these services - be it failure to build locally or on a server or even block a critical deployment. With the packages available in your source control, you have one less moving part in your whole deployment pipeline and it is better to have lesser dependencies.</p>

<h4><strong>Custom Package Sources</strong></h4>

<p>Many times I have had to update my Package sources in Visual Studio and break my head on the specific order of these entries to get the project building. This is very common when using custom packages sources like <a href="http://inedo.com/proget">ProGet</a> or <a href="https://myget.org/">MyGet</a>. Such dependencies make project setup harder and is easily avoided if all the dependent assemblies are available within the repository.  You can still have them as custom NuGet sources but have the dependencies included into the repository and update the references whenever source changes. This makes project ramp up easier and faster, with one less configuration step.</p>

<p><img class="center" alt="Nuget custom package source" src="/images/nuget_package_sources.png" /></p>

<p>Do you still see any reason for not checking in package dependencies into the source control? If not let&rsquo;s go and change that package folder exclude and have them included in the source. (I just updated <a href="http://www.rahulpnath.com/blog/clal-command-line-application-launcher/">CLAL</a> to <a href="https://github.com/rahulpnath/clal/commit/736023d9ab4bd285cb077ff54acd1bbaad142a08">include dependencies.</a>)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[git checkout TFS]]></title>
    <link href="http://rahulpnath.com/blog/git-checkout-tfs/"/>
    <updated>2016-04-15T05:23:08+10:00</updated>
    <id>http://rahulpnath.com/blog/git-checkout-tfs</id>
    <content type="html"><![CDATA[<p>It&rsquo;s been a year since using <a href="https://git-scm.com/">Git</a> as my mainstream version control system and I am loving it! Before Git, I had used Team Foundation Version Control (TFVC) for a very long time and was so used to it that I found Git a bit complex and overwhelming in the beginning. Team Foundation Server (TFS) is the whole product suite from Microsoft that provides source code management. Until TFS 2013, it supported only TFVC which is when it introduced <a href="https://blogs.msdn.microsoft.com/mvpawardprogram/2013/11/13/git-for-tfs-2013/">Git in TFS</a>. Even today people use TFS and TFVC synonymously (like in the title of this post) though they are not the same.</p>

<h3>Fundamental shift in thinking</h3>

<p>By design, Git is a Distributed VCS, whereas TFS is centralized one. It takes quite a while to get your head around this and what it actually means. By definition</p>

<blockquote><p><em><strong>TFVC</strong>: Uses a single, centralized server repository to track and version files. Local changes are always checked in to the central server where other developers can get the latest changes.</em></p>

<p><em><strong>Git</strong>: Git is a distributed version control system. Each developer has a copy of the source repository on their dev machine. Developers can commit each set of changes on their dev machine and perform version control operations such as history and compare without a network connection.</em></p></blockquote>

<p>You. may not see the real Distributed benefits if you are working off a central repository (hosted on a server like GitHub or Bitbucket) and using <a href="https://www.atlassian.com/git/tutorials/comparing-workflows/centralized-workflow">TFS way of development</a> :</p>

<p><em>Get latest code => Make your changes => Merge latest +> Check in (</em>Commit and push<em>)</em></p>

<p>The real power of Git is better understood when you start working disconnected, use branches to keep unrelated development activities separate and merge those into the main trunk (<em>master</em>) once comfortable. You get a local copy of the project and lets you make changes independent of all the other changes in the project.</p>

<blockquote><p><em>Git feels so lightweight and never gets in the way of doing things.</em></p></blockquote>

<h3>Make command line your friend</h3>

<p>If you are a UI savvy person then Git might a good starting point to start using the command line. At first, it definitely feels hard especially if you were TFS/Visual Studio users and might be tempted to use the GUI tools available (<a href="https://desktop.github.com/">GitHub Desktop</a> or <a href="https://www.sourcetreeapp.com/">SourceTree</a>)</p>

<blockquote><p><em>Repetitive tasks become more evident when you use a command line and easily automatable.</em></p></blockquote>

<p>I use Cmder (<a href="http://www.rahulpnath.com/blog/tools-that-I-use/">one of my favourite tools</a>) with Git and have <a href="https://help.github.com/articles/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent/">set up SSH</a> to Bitbucket and Github (expected soon on TFS), secured by a paraphrase, so that I do not have to key in the credentials every time I interact with the repositories. I <a href="https://github.com/cmderdev/cmder/issues/193#issuecomment-63040989">start the ssh-agent the very first time I open Cmder</a>, which prompts for my paraphrase and continues to run in the background. Alternatively, you can also use <a href="https://github.com/Microsoft/Git-Credential-Manager-for-Windows">Credential Manager</a> to store credentials, when working with HTTP enabled Git repository. For the common commands, I have set up aliases like below, to save a bit on the keystrokes.</p>

<pre><code class="text">gl=git log --oneline --all --graph --decorate  $*
gs=git status
ga=git add -A 
gp=git pull
gpp=git push 
gc=git commit -m "$*"  
gcc=git commit
</code></pre>

<h3>Different workflows</h3>

<p>Git can be used in many ways and which makes it hard to get started. There are a few popular <a href="https://www.atlassian.com/git/tutorials/comparing-workflows/">workflows</a> that one can use. Currently, I am using -  <a href="https://www.atlassian.com/git/tutorials/comparing-workflows/feature-branch-workflow">Feature Branch workflow</a> -
which means that all work happen on independent feature branches and once completed gets merged into the main trunk (master branch). Code Reviews happens on the way it gets pulled into the main branch, which ensures code quality and familiarity.</p>

<p><a href="https://www.atlassian.com/git/images/tutorials/collaborating/comparing-workflows/feature-branch-workflow/01.svg"><img class="center" alt="Git Feature Branch Workflow" src="/images/git_featurebranch_workflow.png" /></a></p>

<h3>Not Just for Code</h3>

<p>Git is a version control system and does not limit itself to storing code. You can use it for <a href="http://readwrite.com/2013/11/08/seven-ways-to-use-github-that-arent-coding/">version controlling any of your work</a>. For example, this blog is <a href="https://github.com/rahulpnath/rahulpnath.com">hosted on Github</a> and all the <a href="https://github.com/rahulpnath/rahulpnath.com/commits/master">changes are version controlled</a>, which gives me the flexibility to work and commit locally. Since the blog is <a href="http://www.rahulpnath.com/blog/static-generator-is-all-a-blog-needs-moving-to-octopress/">static generated</a> I can also preview all the changes locally. I use git whenever I work on any documents or <a href="https://github.com/rahulpnath/Speaking">presentations</a> so that I can avoid manual copy of files and renaming with suffixes like &lsquo;<em>Draft</em>, &rsquo;<em>Draft1</em>,<em>Final</em>,&ldquo;<em>FinalRevision</em>&lsquo; etc. (if that sounds any similar)</p>

<h3>Managing Commits</h3>

<p>When coming to commits, which are nothing but checkpoints of meaningful work done, people might have a different  definition for &lsquo;<em>meaningful</em>&rsquo; - for some it might be really granular, for others a bit coarse and for yet another it means all the work is done. I tend to commit quite often - even a rename of a variable leads to a commit so that I do not have to backtrack if at all something goes wrong immediately after that.</p>

<p>if you really like the idea of committing often (locally), but want the pushes to remotes more coarse, you can &lsquo;<strong><a href="http://stackoverflow.com/questions/5189560/squash-my-last-x-commits-together-using-git">squash your commits</a></strong>&rsquo;, before pushing it to remote branch. This allows you to commit often locally and still push  meaningful commit in the main source history. Make sure that the <a href="http://chris.beams.io/posts/git-commit/">commit messages and clear and communicates the intent</a> and helps <a href="http://megakemp.com/2014/08/14/the-importance-of-a-good-looking-history/">keep a good looking history</a>.</p>

<p>Git is one of the best things that happened to developers and hopes it stays long!</p>

<p><strong>References</strong></p>

<ul>
<li><a href="http://gitref.org/index.html">Git Reference</a></li>
<li><a href="https://git-scm.com/book/en/v2">Pro Git</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Being Explicit About Time when Handling Multiple Timezone]]></title>
    <link href="http://rahulpnath.com/blog/being-explicit-about-time-when-handling-multiple-timezone/"/>
    <updated>2016-03-25T06:41:03+11:00</updated>
    <id>http://rahulpnath.com/blog/being-explicit-about-time-when-handling-multiple-timezone</id>
    <content type="html"><![CDATA[<p><em>This article is to put my thoughts together on a possible solution. Challenges of real world implementation are yet to be discovered.</em></p>

<p>Handling date/time in application&rsquo;s that affect different time zones is tricky! The general recommendation is that all dates be saved in UTC time and convert them as required. This works well if developers make sure of converting all dates to UTC at application boundaries and keep it consistent throughout the application.</p>

<p><a href="https://unsplash.com/photos/yBzrPGLjMQw" class="center" title="Image By Heather Zabriskie , from https://unsplash.com/photos/yBzrPGLjMQw"><img src="/images\timezone.jpg" class="center" alt="Timezone"></a></p>

<p>At one of my clients, we are facing similar issues with date time, with an application that deals with different <a href="https://en.wikipedia.org/wiki/Time_zone">time zones</a>. The client sells office spaces across the globe and the application is for their employees to manage their clients. It integrates with various back-end systems and provides a single point of access for everything, aggregating data across those different  systems and itself. Some of the backend systems are in different locations and deal with times local to them. This increases the challenge when sending and retrieving data from them. The application has defined a set of locations, identified by, three-letter codes (<em>SYD, TRV, SEA</em>), and these locations fall under different time zones. Office spaces are at these locations and the application allows to manage those from anywhere.</p>

<p>Across the domain, we use either <a href="https://msdn.microsoft.com/en-us/library/system.datetime(v=vs.110).aspx">DateTime</a> or <a href="https://msdn.microsoft.com/en-us/library/system.datetimeoffset(v=vs.110).aspx">DateTimeOffset</a> to represent time - there is a good recommendation on when to use what - <a href="https://msdn.microsoft.com/en-us/library/bb384267(v=vs.110).aspx">Choosing Between DateTime, DateTimeOffset, TimeSpan, and TimeZoneInfo</a>. The problem with using either is that it does not play well with the domain concept to where time is related to - the location. We do have property name suffixes (not consistent though) indicating whether it is Coordinated Universal Time (UTC) or local - like <em>bookingDateUTC</em>, <em>paymentDateLocal</em> etc. But it so happens that these naming conventions gets broken somewhere along the different layers and leads to conversion between time zone at the application boundary layers.</p>

<h3>Issues with Current Approach</h3>

<p>DateTime and DateTimeOffset have by default time zones attached to it and it might go unnoticed till we face issues.</p>

<ul>
<li>The <a href="https://msdn.microsoft.com/en-us/library/system.datetime.kind(v=vs.110).aspx">Kind</a> property on DateTime indicates whether the time represents a <a href="https://msdn.microsoft.com/en-us/library/shx7s921(v=vs.110).aspx">local time, UTC or neither</a>.</li>
<li>The <a href="https://msdn.microsoft.com/en-us/library/system.datetimeoffset.offset(v=vs.110).aspx">Offset</a> property on DateTimeOffset indicates the time&rsquo;s offset from UTC</li>
</ul>


<p>A common scenario in the current application is user selects a date time in the UI using a date picker, which gets send to the server as a string. This value flows through the entire system and is used to populate external systems. The problem here is that the time zone of the date time is not clear. The developer might treat this as UTC time, system local time or even time local to the location in context. This gives different results to the end user and puts the system in an inconsistent state.</p>

<pre><code class="csharp">public string GetAvailability(string locationCode, DateTime? dateTime)
{
   // Code to Get as on date
}
</code></pre>

<p>Even worse this date time might get converted back and forth to different time zones, even by the same developer or other developers in the team. These conversions implicitly depend on the Kind property and goes unnoticed. One of the most common problems that we see as a result of this is that the dates might fall over to a day before or after or after, depending on where in the world the user, the server running the application is.</p>

<h3>Being Explicit Using Value Objects</h3>

<blockquote><p><em>The issue in dealing with time is about not being explicit. It&rsquo;s a good idea to tie your domain concept (location in this case) and time together</em></p></blockquote>

<p>Since time is always tied to a location (<em>SYD, TRV, SEA</em>) it&rsquo;s better to keep these together. Though DateTimeOffset and DateTime already has a timezone information attached it does not fit well into the domain, it makes more sense to have a <a href="http://www.rahulpnath.com/blog/thinking-beyond-primitive-values-value-objects/">Value Object</a> encapsulating time and location. Timezone by itself is less likely to fit into a domain unless time zones are a domain concept. Most likely the domain would be dealing with a location, place, airport, station etc which falls under a timezone. So it&rsquo;s a good idea to tie your domain concept and the time together. Only for the creation of the Value Object, we need the location after which it is the date time it represents that is relevant. But if by default you want to get back the date time for the same location it was created for, then location can be saved along with the Value Object. In our case, we always want to show the time at the location, so I am keeping it in the Value Object.</p>

<pre><code class="csharp">public class LocationDateTime
{
    public Location Location { get; private set; }
    public DateTime DateTimeInUTC { get; private set; }
    public DateTimeOffset DateTimeAtLocation { get; private set; }

    public LocationDateTime(Location location, DateTime dateTimeUTC)
    {
        if (location == null)
            throw new ArgumentNullException(nameof(location));

        if (dateTimeUTC == null)
            throw new ArgumentNullException(nameof(dateTimeUTC));

        if (dateTimeUTC.Kind != DateTimeKind.Utc)
            throw new ArgumentException("Date Time not in UTC");

        Location = location;
        DateTimeInUTC = dateTimeUTC;
        DateTimeAtLocation = TimeAtLocation(Location);
    }

    public static LocationDateTime AtLocation(DateTime locationDateTime, Location location)
    {
        if (locationDateTime.Kind != DateTimeKind.Unspecified)
            throw new ArgumentException("DateTimeKind should be unspecified");

        var utcTime = TimeZoneInfo.ConvertTimeToUtc(locationDateTime, location.TimeZoneInfo);
        return new LocationDateTime(location, utcTime);
    }

    public DateTimeOffset TimeAtLocation(Location location)
    {
        return TimeZoneInfo.ConvertTime((DateTimeOffset)DateTimeInUTC, location.TimeZoneInfo);
    }

    public override bool Equals(object obj)
    {
        var objAsLocationDateTime = obj as LocationDateTime;
        if ((System.Object)objAsLocationDateTime == null)
            return false;

        return objAsLocationDateTime.DateTimeInUTC == DateTimeInUTC;
    }

    public override int GetHashCode()
    {
        return DateTimeInUTC.GetHashCode();
    }
}
</code></pre>

<p>The Value Object mandates that all date time gets tracked as UTC and allows conversion to time at different locations. The public constructor enforces this by checking the Kind property on DateTime.</p>

<blockquote><p><em>The Value Object Equality is only on the UTC time it represents</em></p></blockquote>

<p><a href="https://github.com/rahulpnath/Blog/blob/master/ExplicitAboutDateTime/ExplicitAboutDateTime/Location.cs">Location</a> is another Value Object, that encapsulates the code, name and the time zone it belongs to. There is a factory method that allows the creation of the value object at a location, which assumes any passed in DateTime as the time at location, and mandates the Kind property is Unspecified. You could update this to accept UTC/Local time depending on the passed in location&rsquo;s time zone, checking if both fall under the same time zone. You can also create an implicit operator to cast to DateTime or DateTimeOffset values and have it return the desired date time value that you want.</p>

<p>All occurrences of datetime in model classes can now be replaced with custom datetime value object. This makes creating a date explicit and mandates developers to make a decision on the location of datetime.</p>

<pre><code class="csharp">public string Get(string locationCode, DateTime? dateTimeAtLocation)
{
    var location = GetLocation(locationCode);
    var locationDateTime = LocationDateTime.AtLocation(dateTimeAtLocation, location);
    // Code to Get as on date
}
</code></pre>

<p>Even with the above code, you cannot restrict what gets passed into the API/application boundary method, but this has made it explicit to the application on how to start treating the date time. This forces the developer to think and be explicit on the time format expected at the boundary. This might lead to better naming of the variables at the boundary - instead of <em>dateTime</em> to <em>dateTimeAtLocation</em> - and being more explicit to the outside world too!</p>

<h3>Custom Factories Using Extension Method</h3>

<p>Depending on the use case there will be a lot of ways you want to create the value object and possibility of some being used over and over again is more. You can use factory methods to help you extract out this code duplication.</p>

<p>As <a href="https://twitter.com/unclebobmartin">Uncle Bob</a> points out in <a href="http://www.amazon.in/gp/product/0131857258/ref=as_li_tl?ie=UTF8&amp;camp=3626&amp;creative=24822&amp;creativeASIN=0131857258&amp;linkCode=as2&amp;tag=rahulpnath-21&amp;linkId=VVMXRINDZWYFRWP4">Agile Principles, Patterns, and Practices in C#</a>, interfaces should be closer to the client. <a href="http://blog.ploeh.dk/2014/12/24/placement-of-abstract-factories/">Factories are nothing but an interface</a>, so it should be defined closer to where it&rsquo;s consumed. Creating a LocationDateTime is always tied to a DateTime object. Using <a href="https://msdn.microsoft.com/en-AU/library/bb383977.aspx">Extension Methods</a> in C#, I have defined an extension on DateTime to create a LocationDateTime object.</p>

<pre><code class="csharp">public static LocationDateTime ToLocationDateTime(this DateTime dateTime, Location location)
{
    if (dateTime == null)
        return null;

    if (location == null)
        throw new ArgumentNullException(nameof(location));

    return LocationDateTime.AtLocation(dateTime, location);
}   
</code></pre>

<p>Now creating a LocationDateTime from a DateTime is easy. Similarly, extension methods can be defined on Location, LocationDateTime to provide custom capabilities as required by the consuming clients.</p>

<pre><code class="csharp">var locationDateTime = dateTimeAtLocation.ToLocationDateTime(location);
</code></pre>

<p>By using a Value Object to represent the DateTime within the application enforces developers to be more explicit on the date time at the boundaries, results in better naming of the variables at boundaries, ensures that it remains the same within the application. You can also override some of the most commonly used operators with DateTime like greater than, less than, equal to, so that it seamlessly fits into the application.</p>

<p>Hoping this will work well in the application too, let me get on to fix it!</p>

<p><em>Will update this post with more real life experiences once implemented!</em></p>
]]></content>
  </entry>
  
</feed>
