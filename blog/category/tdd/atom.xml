<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: tdd | Rahul Nath]]></title>
  <link href="http://rahulpnath.com/blog/category/tdd/atom.xml" rel="self"/>
  <link href="http://rahulpnath.com/"/>
  <updated>2016-01-20T23:20:38+11:00</updated>
  <id>http://rahulpnath.com/</id>
  <author>
    <name><![CDATA[Rahul Nath]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Is Code Coverage a Lie?]]></title>
    <link href="http://rahulpnath.com/blog/is-code-coverage-a-lie/"/>
    <updated>2015-04-11T23:30:42+10:00</updated>
    <id>http://rahulpnath.com/blog/is-code-coverage-a-lie</id>
    <content type="html"><![CDATA[<p>Code Coverage has been one of the important things that was always there on a daily build report and a number that managers were both interested and worried about. This has been the same for all projects that I had worked on, across various organizations. Various tools support measuring coverage and can be included as part of the build reports, which essentially indicates the percentage of source code that is covered by &lsquo;unit tests&rsquo;. A higher percentage obviously indicates a better tested code and more stable one is what one would expect, as that would be the sole purpose of measuring this. But how far is this true? Is a code with higher test percentage one with lesser bugs? Does 100% indicate that it is totally bug free or is this a total wrong way of seeing that number?</p>

<h3>What is Code Coverage and How is it Measured?</h3>

<p>Code Coverage indicates the percentage of code that has been covered by at least one or more tests in your test suite. So if you have a simple function like the one shown below, which just divides two numbers and if you have one test that invokes that function, then you have a code coverage of 100%. When using Visual studio tests (as that is what I have used to depict the below one), code coverage is measured either based on blocks of code or based on lines of code.</p>

<ul>
<li><h4>Block-based statement coverage</h4>

<p>For the purposes of the tools, a block is defined as a sequence of instructions that have a single entry point and a single exit point. Exit points include branch instructions, a function call, a return instruction, or, for managed code, a throw instruction.</p></li>
<li><h4>Line-based coverage</h4>

<p>For line-based coverage, the tools identify all of the blocks that make up a line and then use this information to determine the level of coverage for the line. If all of the blocks that make up the line are covered, then the tools report that the line is covered. If no blocks in the line are covered, then the tools report that the line is not covered. If some, but not all, of the blocks in the line are covered, then the tools report that the line is partially covered.</p></li>
</ul>


<p>In the below case we have both 100% as there is only one line and one block and the test covers both. So should managers be happy with this code, since it has 100% coverage? Maybe they are, but ask the developers, they definitely are not, or probably they are if at the first place they wrote the tests for the sake of the report and since the managers are happy they too are. But is this what we should strive for - definitely not!</p>

<p><img class="center" alt="Visual Studio Code Coverage" src="/images/code_coverage.PNG" /></p>

<h3>Trustworthy Unit Tests</h3>

<blockquote><p>Unit tests should be like a parachute - trustworthy. You are not going to jump out from an airplane with one that you know is faulty.</p></blockquote>

<p>Having unit tests that are run once in a while or just for the build reports or when the manager is at your back, are a complete waste of time. A set of faulty tests do more harm than having none, as it might give wrong judgment of the code. From the above code you can definitely find that though the coverage is 100%, the code would simply fail when a value of 0 is passed for &lsquo;b&rsquo;, and it is highly likely that this would happen too.</p>

<blockquote><p>If unit tests are written just to meet the code coverage number on a report, then I would rather fake the report than writing the tests</p></blockquote>

<p>Unit Tests really make sense only when you write them following &lsquo;<a href="http://butunclebob.com/ArticleS.UncleBob.TheThreeRulesOfTdd">The Three Rules of TDD</a>&rsquo; or at the very least you have tests associated with every change that you make and also you make sure that we run the entire test suite before a check-in to make sure that you have broken nothing with your changes. Only when there is such &lsquo;trustworthiness&rsquo; in the tests, does it make sense to have them in the first place and not for any number on a report.</p>

<h3>How should we really see that number on the report?</h3>

<p>Now that we have seen it is all about having trustworthy tests and not about reaching a targeted number for a report, what should we really use this Code coverage report data for?</p>

<ol>
<li>If you are less than 100% it clearly indicates that there are areas of your application that is not tested. You would really want to cross check if that is an intended miss or if there is something that is actually missing and add in some more tests to be covered better.</li>
<li>When refactoring code, you can always make sure that you don&rsquo;t go back on the coverage number that you started with, so as to ensure that you have not introduced untested code into the system.</li>
<li>When cleaning up tests a drop in the coverage number clearly indicates that you have actually removed some valid and non-redundant tests.</li>
</ol>


<p>So the next time you add in a test, think why you are doing it. Is it for the report or for the application that is getting developed. Lets all <a href="https://vimeo.com/43536488">strive to be really professional</a> in what we are doing and not just hide behind some numbers. Let the number be seen for what it is - nothing less and nothing more!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[TDD andÂ Refactoring]]></title>
    <link href="http://rahulpnath.com/blog/tdd-and-refactoring/"/>
    <updated>2010-08-23T20:42:00+10:00</updated>
    <id>http://rahulpnath.com/blog/tdd-and-refactoring</id>
    <content type="html"><![CDATA[<p>Over the days I have been reading on Test Driven Development(TDD) and it seems really interesting methodology to go with as per development is concerned.<br/>
Basic of TDD is that the development process relies on &lsquo;tests&rsquo;, that are written prior to code.<br/>
Sounds astonishing!!!!<br/>
It might to someone into the normal development mode,where tests are usually written after code, so as to match the code that is written.<br/>
But TDD says just the opposite.<br/>
Code to make the tests pass&hellip;Just pass..<em>Nothing more and Nothing less</em>.<br/>
Thats where the catch is where most of we developers might find it difficult and needs getting used to.Not getting more into it as I would not be the best to comment on it :)<br/>
So whats refactoring got to do here.<br/>
Refactoring plays an integral part of TDD,so that the code is elegant and conveys just what it needs to,avoiding duplication.<br/>
The TDD approach also assists in refactoring as you have tests readily available to assure that the functional behaviour is not affected while changing the code design.You are just click of a button away if you are having a automated test scripts (like nUnit) in veryfying refactoring. <br/>
So both TDD and Refactoring goes hand in hand and helps in greatly improving the overall code quality.<br/>
There are quite a lot resources out there on these.<br/>
The best for refactoring would be of <a href="http://www.amazon.com/gp/product/0201485672/ref=as_li_qf_sp_asin_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=0201485672&amp;linkCode=as2&amp;tag=rahulpnath-20">Refactoring: Improving the Design of Existing Code</a><img src="http://ir-na.amazon-adsystem.com/e/ir?t=rahulpnath-20&amp;l=as2&amp;o=1&amp;a=0201485672" alt="" />.<br/>
For TDD <a href="http://www.amazon.com/gp/product/0735619484/ref=as_li_qf_sp_asin_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=0735619484&amp;linkCode=as2&amp;tag=rahulpnath-20">Test-Driven Development in Microsoft  .NET (Microsoft Professional)</a><img src="http://ir-na.amazon-adsystem.com/e/ir?t=rahulpnath-20&amp;l=as2&amp;o=1&amp;a=0735619484" alt="" /> would be a good start and also the one by Kent Beck <a href="http://www.amazon.com/gp/product/0321146530/ref=as_li_qf_sp_asin_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=0321146530&amp;linkCode=as2&amp;tag=rahulpnath-20">Test Driven Development: By Example</a><img src="http://ir-na.amazon-adsystem.com/e/ir?t=rahulpnath-20&amp;l=as2&amp;o=1&amp;a=0321146530" alt="" /></p>
]]></content>
  </entry>
  
</feed>
